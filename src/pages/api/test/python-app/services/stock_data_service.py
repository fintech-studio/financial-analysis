"""
è‚¡ç¥¨æ•¸æ“šæœå‹™æ¨¡çµ„
ä¸»è¦æ¥­å‹™é‚è¼¯è™•ç†ï¼Œå”èª¿å„å€‹çµ„ä»¶
"""

import logging
import time
from typing import List, Dict, Any, Union
from dataclasses import dataclass
import pandas as pd

from providers.stock_data_provider import (
    StockDataProvider, Period, TimeInterval
)
from calculators.technical_indicators import TechnicalIndicatorCalculator
from repositories.stock_data_repository import StockDataRepository


@dataclass
class ProcessResult:
    """è™•ç†çµæœçµ±è¨ˆ"""
    symbol: str
    success: bool
    new_records: int = 0
    updated_records: int = 0
    indicator_updates: int = 0
    total_records: int = 0
    error_message: str = None
    processing_time: float = 0.0
    date_range: str = None


class ProgressReporter:
    """é€²åº¦å ±å‘Šå™¨"""

    def __init__(self, logger: logging.Logger):
        self.logger = logger

    def info(self, message: str):
        self.logger.info(message)
        print(f"â„¹ï¸  {message}")

    def success(self, message: str):
        self.logger.info(f"SUCCESS: {message}")
        print(f"âœ… {message}")

    def warning(self, message: str):
        self.logger.warning(message)
        print(f"âš ï¸  {message}")

    def error(self, message: str):
        self.logger.error(message)
        print(f"âŒ {message}")

    def progress(self, message: str):
        self.logger.debug(message)
        print(f"ğŸ”„ {message}")


class StockDataService:
    """è‚¡ç¥¨æ•¸æ“šæœå‹™"""

    def __init__(self, config_file: str = "config.ini"):
        self.data_provider = StockDataProvider()
        self.indicator_calculator = TechnicalIndicatorCalculator()
        self.repository = StockDataRepository(config_file)

        # è¨­ç½®æ—¥èªŒ
        self.logger = self._setup_logger()
        self.reporter = ProgressReporter(self.logger)

    def _setup_logger(self) -> logging.Logger:
        """è¨­ç½®æ—¥èªŒè¨˜éŒ„å™¨"""
        logger = logging.getLogger('StockDataService')
        if logger.handlers:
            return logger  # é¿å…é‡è¤‡è¨­ç½®

        logger.setLevel(logging.INFO)

        try:
            file_handler = logging.FileHandler(
                'stock_analyzer.log', encoding='utf-8')
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)
        except Exception:
            pass

        return logger

    def test_connection(self) -> bool:
        """æ¸¬è©¦è³‡æ–™åº«é€£æ¥"""
        try:
            success = self.repository.db_manager.test_connection()
            if success:
                self.reporter.success("è³‡æ–™åº«é€£æ¥æ¸¬è©¦æˆåŠŸ")
            else:
                self.reporter.error("è³‡æ–™åº«é€£æ¥æ¸¬è©¦å¤±æ•—")
            return success
        except Exception as e:
            self.reporter.error(f"è³‡æ–™åº«é€£æ¥æ¸¬è©¦å¤±æ•—: {e}")
            return False

    def process_stock(self, symbol: str,
                      period: Union[Period, str] = Period.YEAR_1,
                      interval: Union[TimeInterval, str] = TimeInterval.DAY_1,
                      check_days: int = 30,
                      expand_history: bool = False) -> ProcessResult:
        """
        è™•ç†å–®ä¸€è‚¡ç¥¨æ•¸æ“š

        Args:
            symbol: è‚¡ç¥¨ä»£è™Ÿ
            period: æŠ“å–æ•¸æ“šçš„æ™‚é–“é€±æœŸ
            interval: æ•¸æ“šé–“éš”
            check_days: æª¢æŸ¥æœ€è¿‘Nå¤©çš„æ•¸æ“šå·®ç•°
            expand_history: æ˜¯å¦æ“´å±•æ­·å²æ•¸æ“šï¼ˆç•¶è¨­ç‚ºTrueæ™‚ï¼Œæœƒå˜—è©¦ç²å–æ¯”è³‡æ–™åº«æ›´æ—©çš„æ­·å²æ•¸æ“šï¼‰
        """
        start_time = time.time()
        result = ProcessResult(symbol=symbol, success=False)

        try:
            # æ¨™æº–åŒ–é–“éš”å­—ç¬¦ä¸²
            interval_str = interval.value if isinstance(
                interval, TimeInterval) else str(interval)

            self.reporter.progress(f"é–‹å§‹è™•ç†è‚¡ç¥¨ {symbol} (é–“éš”: {interval_str})")

            # æ­¥é©Ÿ1: æª¢æŸ¥è³‡æ–™åº«ä¸­çš„ç¾æœ‰æ•¸æ“š
            db_info = self.repository.get_stock_data_info(symbol, interval_str)

            # æ­¥é©Ÿ2: å¾å¤–éƒ¨APIç²å–è‚¡ç¥¨æ•¸æ“š
            external_data = self.data_provider.get_stock_data(
                symbol, period, interval)
            if external_data is None or external_data.empty:
                result.error_message = "ç„¡æ³•ç²å–è‚¡ç¥¨æ•¸æ“š"
                return result

            self.reporter.info(
                f"{symbol} ({interval_str}): ç²å–åˆ° {len(external_data)} ç­†å¤–éƒ¨æ•¸æ“š")

            # æ­¥é©Ÿ3: æ¯”å°æ•¸æ“šä¸¦æ‰¾å‡ºéœ€è¦æ›´æ–°çš„éƒ¨åˆ†
            if db_info['exists']:
                # ç²å–è³‡æ–™åº«ä¸­çš„æ—¥æœŸç¯„åœä¸¦æ¨™æº–åŒ–æ™‚å€
                db_earliest = pd.to_datetime(db_info['earliest_date'])
                db_latest = pd.to_datetime(db_info['latest_date'])

                # ç§»é™¤æ™‚å€è³‡è¨Šä»¥ä¾¿æ¯”è¼ƒ
                if db_earliest.tz is not None:
                    db_earliest = db_earliest.tz_localize(None)
                if db_latest.tz is not None:
                    db_latest = db_latest.tz_localize(None)

                # ç²å–å¤–éƒ¨æ•¸æ“šçš„æ—¥æœŸç¯„åœä¸¦æ¨™æº–åŒ–æ™‚å€
                ext_earliest = external_data.index.min()
                ext_latest = external_data.index.max()

                # ç§»é™¤æ™‚å€è³‡è¨Šä»¥ä¾¿æ¯”è¼ƒ
                if hasattr(ext_earliest, 'tz') and ext_earliest.tz is not None:
                    ext_earliest = ext_earliest.tz_localize(None)
                if hasattr(ext_latest, 'tz') and ext_latest.tz is not None:
                    ext_latest = ext_latest.tz_localize(None)

                self.reporter.info(
                    f"{symbol} ({interval_str}): è³‡æ–™åº«ç¯„åœ {db_earliest.date()} ~ "
                    f"{db_latest.date()}")
                self.reporter.info(
                    f"{symbol} ({interval_str}): å¤–éƒ¨æ•¸æ“šç¯„åœ {ext_earliest.date()} "
                    f"~ {ext_latest.date()}")

                # æ‰¾å‡ºéœ€è¦æ–°å¢çš„æ•¸æ“š
                new_data_parts = []

                # 1. æª¢æŸ¥æ­·å²æ•¸æ“šæ“´å±•ï¼ˆåªåœ¨ expand_history=True æ™‚åŸ·è¡Œï¼‰
                if expand_history and ext_earliest < db_earliest:
                    # ç¢ºä¿å¤–éƒ¨æ•¸æ“šç´¢å¼•ä¹Ÿæ²’æœ‰æ™‚å€è³‡è¨Š
                    external_data_no_tz = external_data.copy()
                    if (hasattr(external_data_no_tz.index, 'tz') and
                            external_data_no_tz.index.tz is not None):
                        external_data_no_tz.index = (
                            external_data_no_tz.index.tz_localize(None))

                    historical_data = external_data_no_tz[
                        external_data_no_tz.index < db_earliest]
                    if not historical_data.empty:
                        new_data_parts.append(('historical', historical_data))
                        self.reporter.info(
                            f"{symbol} ({interval_str}): ç™¼ç¾ "
                            f"{len(historical_data)} ç­†æ›´æ—©çš„æ­·å²æ•¸æ“š")

                # 2. æª¢æŸ¥æœªä¾†æ•¸æ“šï¼ˆæ–°çš„æ•¸æ“šï¼‰
                if ext_latest > db_latest:
                    # ç¢ºä¿å¤–éƒ¨æ•¸æ“šç´¢å¼•ä¹Ÿæ²’æœ‰æ™‚å€è³‡è¨Š
                    external_data_no_tz = external_data.copy()
                    if (hasattr(external_data_no_tz.index, 'tz') and
                            external_data_no_tz.index.tz is not None):
                        external_data_no_tz.index = (
                            external_data_no_tz.index.tz_localize(None))

                    future_data = external_data_no_tz[
                        external_data_no_tz.index > db_latest]
                    if not future_data.empty:
                        new_data_parts.append(('future', future_data))
                        self.reporter.info(
                            f"{symbol} ({interval_str}): ç™¼ç¾ "
                            f"{len(future_data)} ç­†æ–°æ•¸æ“š")

                # 3. æª¢æŸ¥æœ€è¿‘æ•¸æ“šçš„å·®ç•°ï¼ˆç”¨æ–¼æ—¥å¸¸æ›´æ–°ï¼‰
                if not expand_history:  # åªåœ¨éæ“´å±•æ¨¡å¼ä¸‹æª¢æŸ¥æœ€è¿‘æ•¸æ“šå·®ç•°
                    recent_external_data = external_data.tail(check_days)
                    outdated_dates = (
                        self.repository.compare_with_external_data(
                            symbol, recent_external_data, interval_str))

                    if outdated_dates:
                        update_data = external_data.loc[outdated_dates]
                        new_data_parts.append(('updated', update_data))
                        self.reporter.info(
                            f"{symbol} ({interval_str}): ç™¼ç¾ "
                            f"{len(update_data)} ç­†éœ€è¦æ›´æ–°çš„æ•¸æ“š")

                # è™•ç†æ‰€æœ‰éœ€è¦æ›´æ–°çš„æ•¸æ“š
                if new_data_parts:
                    total_updated = 0
                    date_ranges = []

                    for data_type, data_part in new_data_parts:
                        if not data_part.empty:
                            updated_count = self.repository.upsert_ohlcv_data(
                                symbol, data_part, interval_str)
                            total_updated += updated_count

                            start_date = (
                                data_part.index.min().strftime('%Y-%m-%d'))
                            end_date = (
                                data_part.index.max().strftime('%Y-%m-%d'))
                            date_ranges.append(f"{start_date}~{end_date}")

                            type_name = {'historical': 'æ­·å²', 'future': 'æœ€æ–°',
                                         'updated': 'æ›´æ–°'}[
                                data_type]
                            self.reporter.success(
                                f"{symbol} ({interval_str}): è™•ç† "
                                f"{updated_count} ç­†{type_name}æ•¸æ“š")

                    result.updated_records = total_updated
                    result.date_range = ', '.join(date_ranges)

                    # é‡æ–°è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
                    indicator_result = self.update_technical_indicators(
                        symbol, interval_str)
                    result.indicator_updates = indicator_result

                else:
                    if expand_history:
                        self.reporter.info(
                            f"{symbol} ({interval_str}): æ­·å²æ•¸æ“šå·²å®Œæ•´ï¼Œç„¡éœ€æ“´å±•")
                    else:
                        self.reporter.info(
                            f"{symbol} ({interval_str}): æœ€è¿‘ "
                            f"{check_days} å¤©æ•¸æ“šç„¡éœ€æ›´æ–°")
            else:
                # å…¨æ–°è‚¡ç¥¨ï¼Œå„²å­˜æ‰€æœ‰æ•¸æ“š
                saved_count = self.repository.upsert_ohlcv_data(
                    symbol, external_data, interval_str)
                result.new_records = saved_count

                self.reporter.success(
                    f"{symbol} ({interval_str}): å„²å­˜äº† {saved_count} ç­†æ–°æ•¸æ“š")

                # è¨­ç½®æ—¥æœŸç¯„åœ
                start_date = external_data.index.min().strftime('%Y-%m-%d')
                end_date = external_data.index.max().strftime('%Y-%m-%d')
                result.date_range = f"{start_date} ~ {end_date}"

                # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
                indicator_result = self.update_technical_indicators(
                    symbol, interval_str)
                result.indicator_updates = indicator_result

            # æ­¥é©Ÿ5: ç²å–æœ€çµ‚çµ±è¨ˆ
            final_info = self.repository.get_stock_data_info(
                symbol, interval_str)
            result.total_records = final_info.get('record_count', 0)
            result.success = True
            result.processing_time = time.time() - start_time

        except Exception as e:
            result.error_message = str(e)
            result.processing_time = time.time() - start_time
            self.reporter.error(f"{symbol} ({interval_str}): è™•ç†å¤±æ•— - {e}")

        return result

    def update_technical_indicators(self, symbol: str, interval: str = '1d',
                                    full_history: bool = False) -> int:
        """é‡æ–°è¨ˆç®—ä¸¦æ›´æ–°æŠ€è¡“æŒ‡æ¨™

        Args:
            symbol: è‚¡ç¥¨ä»£è™Ÿ
            interval: æ™‚é–“é–“éš”
            full_history: æ˜¯å¦æ›´æ–°å®Œæ•´æ­·å²æ•¸æ“šçš„æŠ€è¡“æŒ‡æ¨™
        """
        try:
            self.reporter.progress(f"{symbol} ({interval}): é–‹å§‹æ›´æ–°æŠ€è¡“æŒ‡æ¨™")

            if full_history:
                # ç²å–æ‰€æœ‰OHLCVæ•¸æ“šç”¨æ–¼è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
                self.reporter.info(f"{symbol} ({interval}): ä½¿ç”¨å®Œæ•´æ­·å²æ¨¡å¼ï¼Œç²å–æ‰€æœ‰æ•¸æ“š")
                ohlcv_data = self.repository.get_all_ohlcv_data(
                    symbol, interval)
            else:
                # ç²å–è¶³å¤ çš„OHLCVæ•¸æ“šç”¨æ–¼è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ï¼ˆè‡³å°‘200å¤©ï¼‰
                ohlcv_data = self.repository.get_latest_ohlcv_data(
                    symbol, interval, days=500)

            if ohlcv_data.empty:
                self.reporter.warning(f"{symbol} ({interval}): ç„¡æ•¸æ“šå¯ç”¨æ–¼è¨ˆç®—æŠ€è¡“æŒ‡æ¨™")
                return 0

            if len(ohlcv_data) < 60:
                self.reporter.warning(
                    f"{symbol} ({interval}): æ•¸æ“šä¸è¶³ï¼ˆ"
                    f"{len(ohlcv_data)} ç­†ï¼‰ï¼Œç„¡æ³•è¨ˆç®—æŠ€è¡“æŒ‡æ¨™")
                return 0

            self.reporter.info(
                f"{symbol} ({interval}): ä½¿ç”¨ {len(ohlcv_data)} ç­†æ•¸æ“šè¨ˆç®—æŠ€è¡“æŒ‡æ¨™")

            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
            indicators = (
                self.indicator_calculator.calculate_indicators_from_ohlcv(
                    ohlcv_data))

            # æ›´æ–°åˆ°è³‡æ–™åº«
            updated_count = self.repository.update_technical_indicators(
                symbol, indicators, interval)

            self.reporter.success(
                f"{symbol} ({interval}): æ›´æ–°äº† {updated_count} ç­†æŠ€è¡“æŒ‡æ¨™")
            return updated_count

        except Exception as e:
            self.reporter.error(f"{symbol} ({interval}): æŠ€è¡“æŒ‡æ¨™æ›´æ–°å¤±æ•— - {e}")
            return 0

    def process_multiple_stocks(self, symbols: List[str],
                                period: Union[Period, str] = Period.YEAR_1,
                                interval: Union[TimeInterval,
                                                str] = TimeInterval.DAY_1,
                                check_days: int = 30,
                                expand_history: bool = False
                                ) -> Dict[str, ProcessResult]:
        """æ‰¹é‡è™•ç†å¤šå€‹è‚¡ç¥¨"""
        interval_str = interval.value if isinstance(
            interval, TimeInterval) else str(interval)

        if expand_history:
            self.reporter.info(
                f"ğŸ”„ æ­·å²æ•¸æ“šæ“´å±•æ¨¡å¼ - é–‹å§‹æ‰¹é‡è™•ç† {len(symbols)} å€‹è‚¡ç¥¨ (é–“éš”: {interval_str})")
            self.reporter.info("å°‡å˜—è©¦ç²å–æ¯”è³‡æ–™åº«æ›´æ—©çš„æ­·å²æ•¸æ“š")
        else:
            self.reporter.info(
                f"é–‹å§‹æ‰¹é‡è™•ç† {len(symbols)} å€‹è‚¡ç¥¨ (é–“éš”: {interval_str})")

        results = {}
        success_count = 0
        total_updates = 0
        total_new_records = 0

        for i, symbol in enumerate(symbols, 1):
            if expand_history:
                print(
                    f"\nğŸ“Š [{i}/{len(symbols)}] æ“´å±•æ­·å²æ•¸æ“š "
                    f"{symbol} ({interval_str})")
            else:
                print(f"\nğŸ“Š [{i}/{len(symbols)}] è™•ç† {symbol} ({interval_str})")

            result = self.process_stock(
                symbol, period, interval, check_days, expand_history)
            results[symbol] = result

            if result.success:
                success_count += 1
                total_updates += result.updated_records
                total_new_records += result.new_records

                if result.updated_records > 0 or result.new_records > 0:
                    print(f"   âœ… æˆåŠŸ | æ–°å¢: {result.new_records} ç­† | "
                          f"æ›´æ–°: {result.updated_records} ç­† | "
                          f"æŒ‡æ¨™: {result.indicator_updates} ç­†")
                    print(f"   ğŸ“… æ™‚é–“ç¯„åœ: {result.date_range}")
                else:
                    print(f"   âœ… æˆåŠŸ | ç„¡éœ€æ›´æ–° | ç¸½è¨ˆ: {result.total_records} ç­†")

                print(f"   â±ï¸  è™•ç†æ™‚é–“: {result.processing_time:.2f} ç§’")
            else:
                print(f"   âŒ å¤±æ•—: {result.error_message}")

        # é¡¯ç¤ºç¸½çµ
        print(f"\n{'='*60}")
        if expand_history:
            print(f"ğŸ“ˆ æ­·å²æ•¸æ“šæ“´å±•å®Œæˆ ({interval_str})")
        else:
            print(f"ğŸ“ˆ æ‰¹é‡è™•ç†å®Œæˆ ({interval_str})")
        print(f"âœ… æˆåŠŸ: {success_count}/{len(symbols)} å€‹è‚¡ç¥¨")
        print(f"ğŸ“Š æ–°å¢è¨˜éŒ„: {total_new_records:,} ç­†")
        print(f"ğŸ“Š æ›´æ–°è¨˜éŒ„: {total_updates:,} ç­†")
        print(f"{'='*60}")

        return results

    def force_update_all_indicators(self, symbols: List[str] = None,
                                    interval: str = '1d',
                                    full_history: bool = True
                                    ) -> Dict[str, int]:
        """å¼·åˆ¶æ›´æ–°æ‰€æœ‰è‚¡ç¥¨çš„æŠ€è¡“æŒ‡æ¨™

        Args:
            symbols: è‚¡ç¥¨ä»£è™Ÿåˆ—è¡¨ï¼Œå¦‚æœç‚ºNoneå‰‡ç²å–æ‰€æœ‰è‚¡ç¥¨
            interval: æ™‚é–“é–“éš”
            full_history: æ˜¯å¦æ›´æ–°å®Œæ•´æ­·å²æ•¸æ“šçš„æŠ€è¡“æŒ‡æ¨™
        """
        if symbols is None:
            symbols = self.repository.get_symbols_list(interval)

        mode_text = "å®Œæ•´æ­·å²" if full_history else "æœ€è¿‘æ•¸æ“š"
        self.reporter.info(
            f"é–‹å§‹å¼·åˆ¶æ›´æ–° {len(symbols)} å€‹è‚¡ç¥¨çš„æŠ€è¡“æŒ‡æ¨™ ({interval}) - {mode_text}æ¨¡å¼")

        results = {}
        for i, symbol in enumerate(symbols, 1):
            print(
                f"\nğŸ”„ [{i}/{len(symbols)}] æ›´æ–° {symbol} ({interval}) "
                f"æŠ€è¡“æŒ‡æ¨™ ({mode_text})")
            updated_count = self.update_technical_indicators(
                symbol, interval, full_history)
            results[symbol] = updated_count

            if updated_count > 0:
                print(f"   âœ… æ›´æ–°äº† {updated_count} ç­†æŠ€è¡“æŒ‡æ¨™")
            else:
                print("   âš ï¸  ç„¡æ›´æ–°æˆ–æ•¸æ“šä¸è¶³")

        return results

    def get_database_statistics(self, interval: str = '1d') -> Dict[str, Any]:
        """ç²å–æŒ‡å®šé–“éš”çš„è³‡æ–™åº«çµ±è¨ˆè³‡è¨Š"""
        return self.repository.get_database_statistics(interval)

    def get_all_database_statistics(self) -> Dict[str, Dict[str, Any]]:
        """ç²å–æ‰€æœ‰é–“éš”è¡¨çš„è³‡æ–™åº«çµ±è¨ˆè³‡è¨Š"""
        return self.repository.get_all_tables_statistics()

    def expand_historical_data(self, symbols: List[str] = None,
                               interval: str = '1d'
                               ) -> Dict[str, ProcessResult]:
        """å°ˆç”¨çš„æ­·å²æ•¸æ“šæ“´å±•åŠŸèƒ½"""
        if symbols is None:
            symbols = self.repository.get_symbols_list(interval)

        self.reporter.info(f"ğŸ”„ é–‹å§‹æ“´å±• {len(symbols)} å€‹è‚¡ç¥¨çš„æ­·å²æ•¸æ“š ({interval})")

        return self.process_multiple_stocks(
            symbols=symbols,
            period=Period.MAX,  # ä½¿ç”¨æœ€å¤§æœŸé–“ä»¥ç²å–æ‰€æœ‰å¯ç”¨çš„æ­·å²æ•¸æ“š
            interval=TimeInterval.DAY_1 if interval == '1d' else interval,
            expand_history=True
        )
