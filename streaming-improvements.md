# AIInsights 元件串流改進

## 主要改進

### 1. 新增 Streaming 狀態管理

- 添加了 `streaming` state 來區分連接階段和內容接收階段
- 在收到第一個內容 chunk 時，從 loading 狀態切換到 streaming 狀態

### 2. 改進的用戶體驗指示器

#### Loading 階段 (連接中)

- 顯示旋轉動畫
- 文字：「正在連接至 AI 模型…」

#### Streaming 階段 (接收內容)

- 頂部顯示藍色脈衝點動畫
- 文字：「AI 正在即時生成分析…」
- 內容區域右上角顯示「即時更新中」標籤
- 底部顯示小的脈衝動畫和「正在接收更多內容」

### 3. 按鈕狀態管理

- 在 streaming 期間禁用重新分析和複製按鈕
- 狀態文字動態更新：連接中 → 正在接收 → 來源

### 4. 視覺反饋改進

- 串流期間內容區域有相對定位的狀態標籤
- 脈衝動畫表示實時更新
- 清晰的階段性用戶反饋

## 技術實作

### 關鍵變更

1. **新增 streaming state**: `const [streaming, setStreaming] = useState(false)`
2. **首次內容檢測**: 使用 `isFirstChunk` 標記來切換狀態
3. **視覺指示器**: 不同階段的動畫和文字提示
4. **狀態清理**: 在重試和錯誤處理中正確重置 streaming 狀態

### 狀態流程

```
初始 → Loading (連接中) → Streaming (接收中) → 完成
```

## 使用效果

用戶現在可以：

1. 清楚知道 AI 何時在連接
2. 看到內容開始串流的即時指示
3. 在內容生成過程中獲得視覺反饋
4. 了解當前處於哪個處理階段

這些改進讓 LLM 輸出的即時性更加明顯，提供了更好的用戶體驗。
